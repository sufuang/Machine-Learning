{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced classes\n",
    "Imbalanced classes appear in many domains, including:\n",
    "* Fraud detection\n",
    "* Spam filtering\n",
    "* Disease screening\n",
    "* SaaS subscription churn\n",
    "\n",
    "## Technique for handling imbalanced classes\n",
    "The  followings are used to tackle the imbalanced classes\n",
    "1. Up-sample Minority Class\n",
    "2. Down-sample Majority Class\n",
    "\n",
    "## Algorithms\n",
    "The following algorithms are used to build a classification model:\n",
    "1. Logistic Regression Algorithm\n",
    "2. SVM Algorithm\n",
    "3. Random Forests Tree Algorithm\n",
    "\n",
    "## Validation\n",
    "The accuracy_score and Area Under ROC Curve (AUROC) are used for the validation.\n",
    "\n",
    "## Notes\n",
    "* Focus purely on addressing imbalanced classes\n",
    "* Not split the dataset into trained/test set\n",
    "* Not tune hyperparameters, or implement cross-validation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset\n",
    "Input: Download from balance-scale.data from http://archive.ics.uci.edu/ml/datasets/balance+scale and rename it as balance_scale_data.txt\n",
    "\n",
    "The dataset contains information about whether a scale is balanced or not, based on weights and distances of the two arms.\n",
    "Target variable - balance \n",
    "Input features  - var1 ~ var4 \n",
    "\n",
    "The target variable has 3 classes:\n",
    "* R for right-heavy, i.e. when var3 * var4 > var1 * var2\n",
    "* L for left-heavy, i.e. when var3 * var4 < var1 * var2\n",
    "* B for balanced, i.e. when var3 * var4 = var1 * var2\n",
    "\n",
    "The target variable 'balance' will be converted to indicator variable\n",
    "0 : target variable with balance  = R or L\n",
    "1 : target variable with balance  = B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\t\n",
    "from  sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input and create an indicator variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  balance  var1  var2  var3  var4\n",
       "0       B     1     1     1     1\n",
       "1       R     1     1     1     2\n",
       "2       R     1     1     1     3\n",
       "3       R     1     1     1     4\n",
       "4       R     1     1     1     5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('balance_scale_data.txt', \n",
    "                 names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L    288\n",
       "R    288\n",
       "B     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['balance'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform into binary classification\n",
    "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
    "df['balance'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate input features (X) and target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model, # Predict on training set and get the accuracy \n",
    "Notes:\n",
    "* The result shows high accuracy. \n",
    "* This model is only predicting 0 and completely ignoring the minority class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Accuracy:0.9216 \n",
      "unique value from predicted result: [0]\n"
     ]
    }
   ],
   "source": [
    "clf_0 = LogisticRegression().fit(X, y)\n",
    "pred_y_0 = clf_0.predict(X)\n",
    "print( \"Score Accuracy:{} \".format(accuracy_score(pred_y_0, y)) )  \n",
    "print( \"unique value from predicted result: {}\".format(np.unique( pred_y_0 )) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-sample Minority Class\n",
    "Up-sampling is the process of randomly duplicating observations from the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    576\n",
      "0    576\n",
      "Name: balance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Upsample minority class \n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=576,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(df_upsampled.balance.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ues Up-sampled dataset to train model and get the accuracy\n",
    "\n",
    "Note: The model is no longer predicting just one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Score Accuracy:0.5138888888888888 \n"
     ]
    }
   ],
   "source": [
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis=1)\n",
    "clf_1 = LogisticRegression().fit(X, y)\n",
    "pred_y_1 = clf_1.predict(X) \n",
    "print( np.unique( pred_y_1 ) )\n",
    "print( \"Score Accuracy:{} \".format(accuracy_score(pred_y_1, y)) ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-sample Minority Class\n",
    "Down-sampling is the process of randomly removing observations from the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    49\n",
      "0    49\n",
      "Name: balance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=49,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "print(df_downsampled.balance.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ues down-sampled dataset to train model and get the accuracy\n",
    "Note: The model is no longer predicting just one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Score Accuracy:0.5816326530612245 \n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_2 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = clf_2.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_2 ) )  # [0 1]\n",
    "print( \"Score Accuracy:{} \".format(accuracy_score(pred_y_2, y)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Your Performance Metric\n",
    "Area Under ROC Curve (AUROC) is a general-purpose metric for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5680966264056644\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_y_2 = clf_2.predict_proba(X)\n",
    " \n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use original dataset to apply SVC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Score Accuracy:0.688 \n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True)\n",
    " \n",
    "clf_3.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(X)\n",
    " \n",
    "# Is the model still predicting just one class?\n",
    "print( np.unique( pred_y_3 ) ) # [0 1]\n",
    " \n",
    "# How's the accuracy?\n",
    "print( \"Score Accuracy:{} \".format(accuracy_score(pred_y_3, y)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46947633219954643\n"
     ]
    }
   ],
   "source": [
    "# What about AUROC?\n",
    "prob_y_3 = clf_3.predict_proba(X)\n",
    "prob_y_3 = [p[1] for p in prob_y_3]\n",
    "print( roc_auc_score(y, prob_y_3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use original dataset to apply Random Forests algorithm\n",
    "Note:\n",
    "The Score Accuracy and roc_auc_score are excellent. However the model might overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Score Accuracy:0.9776 \n",
      "roc_auc_score: 0.9967403628117915\n"
     ]
    }
   ],
   "source": [
    "clf_4 = RandomForestClassifier()\n",
    "clf_4.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_4 = clf_4.predict(X)\n",
    " \n",
    "# Is the model still predicting just one class?\n",
    "print( np.unique( pred_y_4 ) ) \n",
    " \n",
    "# How's is accuracy?\n",
    "print( \"Score Accuracy:{} \".format(accuracy_score(pred_y_4, y)) )\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y_4 = clf_4.predict_proba(X)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print(  \"roc_auc_score: {}\".format(roc_auc_score(y, prob_y_4)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
